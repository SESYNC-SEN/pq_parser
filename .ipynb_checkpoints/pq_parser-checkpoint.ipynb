{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse ProQuest Metadata\n",
    "Python function to parse newspaper articles downloaded from ProQuest Global Newsstream as .txt files in batches of 100.\n",
    "Created by Cody Hennesy and David Naughton, University of Minnesota, Twin Cities, Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: import libraries\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes a directory (full of .txt files from PQ) as its argument.\n",
    "For example: `parsePQ(\"txt_input/\")`\n",
    "\n",
    "It assumes you will run the script in a directory with an `output/` folder where the CSV files will be output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"____________________________________________________________\"\n",
    "\n",
    "## function that takes a directory of .txt files from ProQuest as input \n",
    "def parsePQ(path): \n",
    "    \n",
    "    #cycle through every text file in the directory given as an argument\n",
    "    files_all = glob.iglob(path + \"*.txt\")\n",
    "    for filename in files_all:\n",
    "        \n",
    "        #remove the path, whitespace, and '.txt' from filename to later use when naming output\n",
    "        file_id = filename[:-4].strip(path).replace(\" \", \"\")\n",
    "        \n",
    "        with open(filename, 'r') as in_file:\n",
    "            # text var for string of all docs\n",
    "            text = in_file.read()\n",
    "\n",
    "            # split string by separator into single articles\n",
    "            docs = re.split(sep, text)\n",
    "\n",
    "            # remove first and last items from docs list: first item is empty string; last is copyright info\n",
    "            docs = docs[1:-1]\n",
    "\n",
    "            # open a csv file to write metadata to\n",
    "            with open('output/' + file_id + '.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "                #declare fields to capture; can add fields as needed\n",
    "                fieldnames = ['Title', 'Publication title', 'Publication year', 'Document URL', 'Full text']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "                writer.writeheader()\n",
    "\n",
    "                # loop through every doc to collect metadata and full text\n",
    "                for doc in docs:\n",
    "\n",
    "                    # remove white space from beginning and end of each article\n",
    "                    doc = doc.strip()\n",
    "\n",
    "                    # skip any empty docs\n",
    "                    if doc==\"\":\n",
    "                        continue\n",
    "\n",
    "                    # split doc on every new line\n",
    "                    metadata_lines = doc.split('\\n\\n')\n",
    "\n",
    "                    #remove first \"line\" from article which is the article title without any field title\n",
    "                    metadata_lines = metadata_lines[1:]\n",
    "\n",
    "                    #declare a new dictionary\n",
    "                    metadata_dict = {}\n",
    "\n",
    "                    #for each element add the fieldname/key and following value to a dictionary\n",
    "                    for line in metadata_lines:\n",
    "\n",
    "                        #ignore lines that do not have a field beginning \"Xxxxxx:\" (e.g. \"Publication title: \")\n",
    "                        if not re.match(r'^[^:]+: ', line):\n",
    "                            continue\n",
    "                        #looks for beginning of new line following structure of \"Publication year: \" splitting on the colon space\n",
    "                        (key,value) = line.split(sep=': ', maxsplit=1)\n",
    "\n",
    "                        #only add to dictionary if the key is in fieldnames\n",
    "                        if key in fieldnames:\n",
    "                            metadata_dict[key] = value\n",
    "\n",
    "                    #write the dictionary values to new row in csv\n",
    "                    writer.writerow(metadata_dict)\n",
    "            print(\"Writing\", file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ProQuestDocuments-2019-07-29\n",
      "Writing ProQuestDocuments-2019-07-14\n",
      "Writing ProQuestDocuments-2019-07-29(1)\n"
     ]
    }
   ],
   "source": [
    "#run the script\n",
    "parsePQ(\"txt_input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
